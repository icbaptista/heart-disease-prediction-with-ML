{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzzzz151/TAA-Project1/blob/master/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFmSuXqe_GCG"
      },
      "outputs": [],
      "source": [
        "#Import relevant libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import learning_curve, validation_curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column 1: age in years\n",
        "# Column 2: 1 = male, 0 = female\n",
        "# Column 3: 1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptomatic\n",
        "# Column 4: resting blood pressure in mmHg\n",
        "# Column 5: in mg/dl\n",
        "# Column 6: 1 means > 120 mg/dl, 0 means <= 120 mg/dl\n",
        "# Column 7: resting electrocardiographic, 0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "# Column 8: max heart rate achieved\n",
        "# Column 9: 1 = yes, 2 = no\n",
        "# Column 10: ST depression induced by exercise relative to rest\n",
        "# Column 11: slope of the peak exercise ST segment, 1 = upsloping, 2 = flat, 3 = downsloping\n",
        "# Column 12: number of major vessels (0-3) colored by flourosopy\n",
        "# Column 13: 3 = normal, 6 = fixed defect, 7 = reversable defect\n",
        "# Column 14: >=1 means heart disease, 0 = no heart disease\n",
        "\n",
        "myNames = [\"age\", # column 1\n",
        "        \"sex\", # col 2\n",
        "        \"chestPainType\", # col 3\n",
        "        \"restingBP\", # col 4\n",
        "        \"serumCholesterol\", # col 5\n",
        "        \"fastingBloodSugar\", # col 6\n",
        "        \"restingEcg\", # col 7\n",
        "        \"maxHeartRate\", # col 8\n",
        "        \"exerciseInducedAngina\", # col 9\n",
        "        \"stDepression\", # col 10\n",
        "        \"stSlope\", # col 11\n",
        "        \"majorVessels\", # col 12\n",
        "        \"thalassemia\", # col 13\n",
        "        \"diagnosis\"] # col 14\n",
        "assert len(myNames) == 14\n",
        "data=pd.read_csv(\"data/processed.cleveland.data\", sep=',', names=myNames, na_values=[\"?\", '?'])\n",
        "data = data.dropna() # Drop rows with missing data\n",
        "\n",
        "# Convert all columns to float\n",
        "for name in myNames:\n",
        "    data[name] = pd.to_numeric(data[name],errors = 'coerce')\n",
        "\n",
        "X = data.values[:, :-1]\n",
        "y = data.values[:, -1:]\n",
        "y = np.clip(y, a_min=0, a_max=1) # Clip values in the array to be between 0 and 1, both inclusive\n",
        "\n",
        "m = data.shape[0] # num examples\n",
        "n = data.shape[1] - 1 # num features\n",
        "\n",
        "print(m)\n",
        "print(n)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos=(y==1)\n",
        "neg=(y==0)\n",
        "plt.scatter(X[pos[:,0],0],X[pos[:,0],7],c=\"r\",marker=\"+\", label = \"Has heart disease\")\n",
        "plt.scatter(X[neg[:,0],0],X[neg[:,0],7],c=\"b\",marker=\"o\", label = \"No heart disease\")\n",
        "\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Max heart rate\")\n",
        "#plt.ylim(,200)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unregularized Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the neural network model with two hidden layers, each with 20 neurons\n",
        "model = MLPClassifier(hidden_layer_sizes=(25, 25), activation='relu', solver='adam', max_iter=500)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict training set labels\n",
        "y_pred_train = model.predict(X_train)\n",
        "num_iterations = model.n_iter_\n",
        "\n",
        "print(\"Training number of Iterations: \", num_iterations)\n",
        "\n",
        "# Calculate the training accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print training accuracy\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Print test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Use k-fold cross-validation to estimate the accuracy of the model\n",
        "cv_scores = cross_val_score(model, X, y.ravel(), cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV score:\", mean_cv_score)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Print confusion matrix with labels\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"                Predicted No    Predicted Yes\")\n",
        "print(\"Actual No        \", tn, \"            \", fp)\n",
        "print(\"Actual Yes       \", fn, \"             \", tp)\n",
        "\n",
        "# Generate classification report\n",
        "cr = classification_report(y_test, y_pred_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(cr)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the range of training set sizes\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    model, X, y.ravel(), cv=5, train_sizes=train_sizes, scoring='accuracy')\n",
        "\n",
        "# Calculate the mean and standard deviation of the training and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, label='Training Accuracy')\n",
        "plt.plot(train_sizes, test_mean, label='Testing Accuracy')\n",
        "\n",
        "# Plot the shaded area representing the standard deviation\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the validation loss from the model\n",
        "validation_loss = model.loss_curve_\n",
        "\n",
        "# Plot the validation loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(validation_loss, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Validation Loss over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing different learning rates and Number of Neurons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]  # Specify different learning rates\n",
        "neurons = [10, 20, 30, 40, 50]  # Specify different number of neurons\n",
        "\n",
        "# Learning Rate Curve\n",
        "param_range_lr = learning_rates\n",
        "train_scores_lr, test_scores_lr = validation_curve(\n",
        "    MLPClassifier(max_iter=500),\n",
        "    X_train, y_train.ravel(),\n",
        "    param_name='learning_rate_init',\n",
        "    param_range=param_range_lr,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Number of Neurons Curve\n",
        "param_range_neurons = neurons\n",
        "train_scores_neurons, test_scores_neurons = validation_curve(\n",
        "    MLPClassifier(max_iter=500),\n",
        "    X_train, y_train.ravel(),\n",
        "    param_name='hidden_layer_sizes',\n",
        "    param_range=param_range_neurons,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Plotting the curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Learning Rate Curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(learning_rates, np.mean(train_scores_lr, axis=1), marker='o', label='Training Score')\n",
        "plt.plot(learning_rates, np.mean(test_scores_lr, axis=1), marker='o', label='Validation Score')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Learning Rate Curve')\n",
        "plt.legend()\n",
        "\n",
        "# Number of Neurons Curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(neurons, np.mean(train_scores_neurons, axis=1), marker='o', label='Training Score')\n",
        "plt.plot(neurons, np.mean(test_scores_neurons, axis=1), marker='o', label='Validation Score')\n",
        "plt.xlabel('Number of Neurons')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Number of Neurons Curve')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning using GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "# GridSearchCV performs exaustive search over a specified hyperparameter space to find the best model with the highest cross validation score\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(10,), (20,), (30,), (10,10), (20,20), (30,30)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train.ravel())\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Print the accuracy of the best model\n",
        "print(\"Best Cross Validation Score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new model object with the optimal hyperparameters\n",
        "optimal_model = MLPClassifier(**grid_search.best_params_)\n",
        "\n",
        "# Train the model on the training data\n",
        "optimal_model.fit(X_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict training set labels\n",
        "y_pred_train = optimal_model.predict(X_train)\n",
        "num_iterations = optimal_model.n_iter_\n",
        "\n",
        "print(\"Training number of Iterations: \", num_iterations)\n",
        "\n",
        "# Calculate the training accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print training accuracy\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred_test = optimal_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Print test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Use k-fold cross-validation to estimate the accuracy of the model\n",
        "cv_scores = cross_val_score(optimal_model, X, y.ravel(), cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV score:\", mean_cv_score)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Print confusion matrix with labels\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"                Predicted No    Predicted Yes\")\n",
        "print(\"Actual No        \", tn, \"            \", fp)\n",
        "print(\"Actual Yes       \", fn, \"             \", tp)\n",
        "\n",
        "# Generate classification report\n",
        "cr = classification_report(y_test, y_pred_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(cr)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the range of training set sizes\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    optimal_model, X, y.ravel(), cv=5, train_sizes=train_sizes, scoring='accuracy')\n",
        "\n",
        "# Calculate the mean and standard deviation of the training and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, label='Training Accuracy')\n",
        "plt.plot(train_sizes, test_mean, label='Testing Accuracy')\n",
        "\n",
        "# Plot the shaded area representing the standard deviation\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regularized version of Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "alpha_values = [0.0001, 0.001, 0.01, 0.1, 1, 5, 10]  # Specify different alpha values\n",
        "\n",
        "# Create an empty list to store the cross-validation scores and training accuracy scores\n",
        "cv_scores = []\n",
        "train_scores = []\n",
        "\n",
        "# Perform grid search with cross-validation for each alpha value\n",
        "for alpha in alpha_values:\n",
        "    # Create the neural network model with two hidden layers, each with 30 neurons and the current alpha value\n",
        "    model = MLPClassifier(hidden_layer_sizes=(30, 30), activation='relu', solver='adam', max_iter=500, alpha=alpha)\n",
        "    \n",
        "    # Perform cross-validation to get the cross-validation scores\n",
        "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
        "    cv_scores.append(cv_score)\n",
        "    \n",
        "    # Perform cross-validation again to get the training accuracy scores\n",
        "    train_score = np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))\n",
        "    train_scores.append(train_score)\n",
        "\n",
        "best_alpha_index = np.argmax(cv_scores)\n",
        "best_alpha = alpha_values[best_alpha_index]\n",
        "\n",
        "print(\"Best Alpha Parameter:\", best_alpha)\n",
        "\n",
        "# Plot the line graph of cross-validation scores and training accuracy scores\n",
        "plt.figure(figsize=(8, 6))  # Set the figure size\n",
        "\n",
        "plt.plot(alpha_values, cv_scores, linestyle='--', marker='o', color='b', label='Cross-Validation Score')\n",
        "plt.plot(alpha_values, train_scores, linestyle='--', marker='o', color='r', label='Training Accuracy Score')\n",
        "\n",
        "plt.xlabel('Alpha (Regularization Strength)')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Cross-Validation Scores and Training Accuracy Scores for Different Alpha Values')\n",
        "plt.legend()\n",
        "plt.grid(True)  # Display grid lines\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOXKawVB+liuyGJifYajyVM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
