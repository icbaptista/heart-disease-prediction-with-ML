{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461da679",
   "metadata": {},
   "source": [
    "**Imports and data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd080dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(y==1):  137\n",
      "len(y==0): 160\n"
     ]
    }
   ],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "myNames = [\"age\", # column 1\n",
    "        \"sex\", # col 2\n",
    "        \"chestPainType\", # col 3\n",
    "        \"restingBP\", # col 4\n",
    "        \"serumCholesterol\", # col 5\n",
    "        \"fastingBloodSugar\", # col 6\n",
    "        \"restingEcg\", # col 7\n",
    "        \"maxHeartRate\", # col 8\n",
    "        \"exerciseInducedAngina\", # col 9\n",
    "        \"stDepression\", # col 10\n",
    "        \"stSlope\", # col 11\n",
    "        \"majorVessels\", # col 12\n",
    "        \"thalassemia\", # col 13\n",
    "        \"diagnosis\"] # col 14\n",
    "assert len(myNames) == 14\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"data/processed.cleveland.data\", sep=',', names=myNames, na_values=[\"?\", '?'])\n",
    "data = data.dropna() # Drop rows with missing data\n",
    "data.iloc[:, -1] = data.iloc[:, -1].clip(0, 1) # make last column is 0's and 1's\n",
    "\n",
    "# Convert all columns to float\n",
    "for name in myNames:\n",
    "        data[name] = pd.to_numeric(data[name],errors = 'coerce')\n",
    "        \n",
    "num_ones = data.iloc[:, -1].value_counts()[1]\n",
    "print(\"len(y==1): \", num_ones)\n",
    "num_zeros = data.iloc[:, -1].value_counts()[0]\n",
    "print(\"len(y==0):\",  num_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24930cc",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef07643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg Unregularized\n",
      "No penalty\n",
      "Accuracy (% correct predicts) 0.87\n",
      "\n",
      "Log Reg Regularized\n",
      "Penalty l2\n",
      "Best C 0.05\n",
      "Accuracy (% correct predicts) 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"diagnosis\", axis=1), data[\"diagnosis\"], test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)   \n",
    "\n",
    "def train(argPenalty=None, argC=[0.01, 0.05, 0.1, 0.3, 0.5,  0.8, 1, 2, 5]):\n",
    "    if not argPenalty:\n",
    "        model = LogisticRegression(max_iter=10000)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(\"Log Reg Unregularized\")\n",
    "        print(\"No penalty\")\n",
    "        print(\"Accuracy (% correct predicts)\", round(accuracy, 2))\n",
    "    else:\n",
    "        bestAcc = 0\n",
    "        bestC = None\n",
    "        for myC in argC:\n",
    "            model = LogisticRegression(max_iter=10000, penalty=argPenalty, C=myC)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > bestAcc:\n",
    "                bestAcc = accuracy\n",
    "                bestC = myC\n",
    "        print(\"Log Reg Regularized\")\n",
    "        print(\"Penalty \" + argPenalty)\n",
    "        print(\"Best C\", bestC)\n",
    "        print(\"Accuracy (% correct predicts)\", round(bestAcc,2))\n",
    "\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    print(\"Balanced accuracy:\", round(balanced_accuracy,2))\n",
    "    print(\"Precision:\", round(precision, 2))\n",
    "    print(\"Recall:\", round(recall, 2))\n",
    "    print(\"F1-score:\", round(f1, 2))\n",
    "    \"\"\"\n",
    "    \n",
    "train()\n",
    "print()\n",
    "train(\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a89247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, \\\n",
    "    classification_report\n",
    "\n",
    "# Encode the categorical variables\n",
    "# It transforms each unique value of the categorical variable into a separate binary variable.\n",
    "# Multiple columns of True/False values\n",
    "data_encoded = pd.get_dummies(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_encoded.drop('diagnosis', axis=1)\n",
    "y = data_encoded['diagnosis']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "\n",
    "# Fit a logistic regression model to the training set\n",
    "# increase the maximum number of iterations and specify the solver\n",
    "model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the performance of the model\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "\n",
    "# Create decision tree classifier with default settings\n",
    "dt = DecisionTreeClassifier(random_state=60)\n",
    "\n",
    "# Fit the decision tree on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert categorical variables to dummies\n",
    "data_encoded = pd.get_dummies(data, columns=[\"chestPainType\", \"restingEcg\", \"stSlope\", \"thalassemia\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_encoded.drop('diagnosis', axis=1)\n",
    "y = data_encoded['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=60)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, \\\n",
    "    classification_report\n",
    "\n",
    "# Encode the categorical variables\n",
    "data_encoded = pd.get_dummies(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data_encoded.drop('diagnosis', axis=1)\n",
    "y = data_encoded['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "\n",
    "# Fit a GBM model to the training set\n",
    "model = GradientBoostingClassifier(random_state=60, learning_rate=0.1, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the performance of the model\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the neural network\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the neural network\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6633775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
